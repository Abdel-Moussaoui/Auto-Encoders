{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "convolutional_autoencoder.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMxwKXmdK6eYGP9Qr0yxw5s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abdel-Moussaoui/Auto-Encoders/blob/master/convolutional_autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43BfmBCQYW6d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "64ec4b63-c3b0-419e-c099-3ce476cea079"
      },
      "source": [
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from keras.models import Model\n",
        "from keras.datasets import mnist\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "input_img = Input(shape=(28, 28, 1))    # adapt this if using 'channels_first' image data format\n",
        "\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# at this point the representation is (4, 4, 8), i.e. 128-dimensional\n",
        "\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
        "\n",
        "# To train it, use the original MNIST digits with shape (samples, 3, 28, 28),\n",
        "# and just normalize pixel values between 0 and 1\n",
        "\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))    # adapt this if using 'channels_first' image data format\n",
        "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))       # adapt this if using 'channels_first' image data format\n",
        "\n",
        "# open a terminal and start TensorBoard to read logs in the autoencoder subdirectory\n",
        "# tensorboard --logdir=autoencoder\n",
        "\n",
        "autoencoder.fit(x_train, x_train, epochs=50, batch_size=128, shuffle=True, validation_data=(x_test, x_test),\n",
        "                callbacks=[TensorBoard(log_dir='conv_autoencoder')], verbose=2)\n",
        "\n",
        "# take a look at the reconstructed digits\n",
        "decoded_imgs = autoencoder.predict(x_test)\n",
        "\n",
        "n = 10\n",
        "plt.figure(figsize=(10, 4), dpi=100)\n",
        "for i in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.set_axis_off()\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i + n + 1)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.set_axis_off()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# take a look at the 128-dimensional encoded representation\n",
        "# these representations are 8x4x4, so we reshape them to 4x32 in order to be able to display them as grayscale images\n",
        "\n",
        "encoder = Model(input_img, encoded)\n",
        "encoded_imgs = encoder.predict(x_test)\n",
        "\n",
        "# save latent space features 128-d vector\n",
        "pickle.dump(encoded_imgs, open('conv_autoe_features.pickle', 'wb'))\n",
        "\n",
        "n = 10\n",
        "plt.figure(figsize=(10, 4), dpi=100)\n",
        "for i in range(n):\n",
        "    ax = plt.subplot(1, n, i + 1)\n",
        "    plt.imshow(encoded_imgs[i].reshape(4, 4 * 8).T)\n",
        "    plt.gray()\n",
        "    ax.set_axis_off()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "K.clear_session()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}