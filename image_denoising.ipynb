{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_denoising.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPYRiGHDK+01K0LqeM65Uc3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abdel-Moussaoui/Auto-Encoders/blob/master/image_denoising.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUgtvtO3d4UM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "1b156177-c35c-4478-a3aa-e9abcafb218f"
      },
      "source": [
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from keras.models import Model\n",
        "from keras.datasets import mnist\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "input_img = Input(shape=(28, 28, 1))    # adapt this if using 'channels_first' image data format\n",
        "\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# at this point the representation is (7, 7, 32)\n",
        "\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
        "\n",
        "# To train it, use the original MNIST digits with shape (samples, 3, 28, 28),\n",
        "# and just normalize pixel values between 0 and 1\n",
        "\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))    # adapt this if using 'channels_first' image data format\n",
        "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))       # adapt this if using 'channels_first' image data format\n",
        "\n",
        "noise_factor = 0.5\n",
        "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)\n",
        "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)\n",
        "\n",
        "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
        "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
        "\n",
        "# open a terminal and start TensorBoard to read logs in the autoencoder subdirectory\n",
        "# tensorboard --logdir=autoencoder\n",
        "\n",
        "autoencoder.fit(x_train_noisy, x_train, epochs=100, batch_size=128, shuffle=True,\n",
        "                validation_data=(x_test_noisy, x_test), verbose=2,\n",
        "                callbacks=[TensorBoard(log_dir='noisy', histogram_freq=0, write_grads=False)])\n",
        "\n",
        "# take a look at the reconstructed digits\n",
        "decoded_imgs = autoencoder.predict(x_test)\n",
        "\n",
        "n = 10\n",
        "plt.figure(figsize=(10, 4), dpi=100)\n",
        "for i in range(n):\n",
        "    # display noisy\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.set_axis_off()\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i + n + 1)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.set_axis_off()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# take a look at the x-dimensional encoded representation\n",
        "# these representations are 32x7x7, so we reshape them in order to be able to display them as grayscale images\n",
        "\n",
        "encoder = Model(input_img, encoded)\n",
        "encoded_imgs = encoder.predict(x_test)\n",
        "\n",
        "# save latent space features 1568-d vector\n",
        "pickle.dump(encoded_imgs, open('denoise_autoe_features.pickle', 'wb'))\n",
        "\n",
        "n = 10\n",
        "plt.figure(figsize=(10, 4), dpi=100)\n",
        "for i in range(n):\n",
        "    ax = plt.subplot(1, n, i + 1)\n",
        "    plt.imshow(encoded_imgs[i].reshape(7, 7 * 32).T)\n",
        "    plt.gray()\n",
        "    ax.set_axis_off()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "K.clear_session()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}